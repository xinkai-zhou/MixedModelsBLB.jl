var documenterSearchIndex = {"docs":
[{"location":"man/contributing/#Contributing","page":"Contributing","title":"Contributing","text":"","category":"section"},{"location":"man/contributing/","page":"Contributing","title":"Contributing","text":"We'd welcome contributions to the MixedModelsBLB.jl package. ","category":"page"},{"location":"man/contributing/","page":"Contributing","title":"Contributing","text":"If you don't know what you'd like to contribute, you could ","category":"page"},{"location":"man/contributing/","page":"Contributing","title":"Contributing","text":"take a look at the current issues and pick one\nadd more usage examples.","category":"page"},{"location":"man/contributing/","page":"Contributing","title":"Contributing","text":"Then submit a pull request (PR). Let us know if it's a work in progress by putting [WIP] in the name of the PR.","category":"page"},{"location":"man/detailed-usage/#Detailed-Usage","page":"Detailed Usage","title":"Detailed Usage","text":"","category":"section"},{"location":"man/detailed-usage/","page":"Detailed Usage","title":"Detailed Usage","text":"This page covers options you will need for dealing with extremely large longitudinal data sets and for forming estimates and confidence intervals of functions of the parameter estimates. ","category":"page"},{"location":"man/detailed-usage/#Data-Input","page":"Detailed Usage","title":"Data Input","text":"","category":"section"},{"location":"man/detailed-usage/","page":"Detailed Usage","title":"Detailed Usage","text":"As shown in the Quick Tutorial section, data can be loaded in memory (RAM) as a DataFrame. However, real-world longitudinal data such as Electronic Meidcal Records (EMR) may be too large to fit in RAM. ","category":"page"},{"location":"man/detailed-usage/","page":"Detailed Usage","title":"Detailed Usage","text":"Fortunately, since the Bag of Little Bootstrap (BLB) method operates on subsets rather than the full data set, we do not need to load the full data in RAM. By interfacing with a database, we stream in subsets that are relevant to the analysis and leave the rest of the data on the hard disk. ","category":"page"},{"location":"man/detailed-usage/","page":"Detailed Usage","title":"Detailed Usage","text":"To illustrate, we created a MySQL database called MixedModelsBLB on the local host and imported a simulated longitudinal data set with 1000 subjects and 20 measurements per subject to the testdata table. Covariates x_1 x_2 x_3 z_1 are simulated from standard normal. ","category":"page"},{"location":"man/detailed-usage/","page":"Detailed Usage","title":"Detailed Usage","text":"By providing a connection object, the blb_db function can interface with the database and only fetch data subsets that are relevant to the analysis. ","category":"page"},{"location":"man/detailed-usage/","page":"Detailed Usage","title":"Detailed Usage","text":"using MixedModelsBLB, StatsModels, Random, Ipopt, DBInterface, MySQL, DataFrames","category":"page"},{"location":"man/detailed-usage/","page":"Detailed Usage","title":"Detailed Usage","text":"con = DBInterface.connect(MySQL.Connection, \"127.0.0.1\", \"USERNAME\", \"PASSWORD\"; db = \"MixedModelsBLB\");","category":"page"},{"location":"man/detailed-usage/","page":"Detailed Usage","title":"Detailed Usage","text":"# Show the first 10 rows of the data set\nDBInterface.execute(con,  \"SELECT * FROM testdata LIMIT 10;\") |> DataFrame","category":"page"},{"location":"man/detailed-usage/","page":"Detailed Usage","title":"Detailed Usage","text":"<table class=\"data-frame\"><thead><tr><th></th><th>id</th><th>y</th><th>x1</th><th>x2</th><th>x3</th><th>z1</th></tr><tr><th></th><th>Int32</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th></tr></thead><tbody><p>10 rows × 6 columns</p><tr><th>1</th><td>1</td><td>-1.74387</td><td>-1.72976</td><td>-1.28905</td><td>-1.47062</td><td>-0.267067</td></tr><tr><th>2</th><td>1</td><td>1.23021</td><td>0.795949</td><td>-0.33527</td><td>-0.535211</td><td>1.49908</td></tr><tr><th>3</th><td>1</td><td>0.495366</td><td>0.670062</td><td>0.0704676</td><td>-0.963544</td><td>0.797304</td></tr><tr><th>4</th><td>1</td><td>1.79272</td><td>0.550852</td><td>0.341794</td><td>-1.38511</td><td>-0.17164</td></tr><tr><th>5</th><td>1</td><td>3.33667</td><td>-0.0633746</td><td>1.73517</td><td>0.1343</td><td>-0.46908</td></tr><tr><th>6</th><td>1</td><td>4.35921</td><td>1.33694</td><td>1.29992</td><td>-0.616117</td><td>0.217624</td></tr><tr><th>7</th><td>1</td><td>3.05776</td><td>-0.0731486</td><td>0.206364</td><td>-1.71999</td><td>0.359146</td></tr><tr><th>8</th><td>1</td><td>-0.493603</td><td>-0.745464</td><td>-1.00886</td><td>0.320769</td><td>0.320025</td></tr><tr><th>9</th><td>1</td><td>-1.31595</td><td>-1.22006</td><td>-0.850056</td><td>-1.44737</td><td>0.259216</td></tr><tr><th>10</th><td>1</td><td>-0.446968</td><td>-0.0531773</td><td>1.12941</td><td>-0.492271</td><td>0.459696</td></tr></tbody></table>","category":"page"},{"location":"man/detailed-usage/","page":"Detailed Usage","title":"Detailed Usage","text":"solver = Ipopt.IpoptSolver(print_level=0, max_iter=100, \n    mehrotra_algorithm = \"yes\", warm_start_init_point = \"yes\", \n    warm_start_bound_push = 1e-9)\n\nblb_ests = blb_db(\n        MersenneTwister(1),\n        con,\n        \"testdata\",\n        feformula   = @formula(y ~ 1 + x1 + x2 + x3),\n        reformula   = @formula(y ~ 1 + z1),\n        id_name     = \"id\", \n        cat_names   = Vector{String}(), \n        subset_size = 200,\n        n_subsets   = 10, \n        n_boots     = 500,\n        solver      = solver,\n        verbose     = false,\n        nonparametric_boot = true\n    );","category":"page"},{"location":"man/detailed-usage/","page":"Detailed Usage","title":"Detailed Usage","text":"******************************************************************************\nThis program contains Ipopt, a library for large-scale nonlinear optimization.\n Ipopt is released as open source code under the Eclipse Public License (EPL).\n         For more information visit https://github.com/coin-or/Ipopt\n******************************************************************************","category":"page"},{"location":"man/detailed-usage/","page":"Detailed Usage","title":"Detailed Usage","text":"print(blb_ests)","category":"page"},{"location":"man/detailed-usage/","page":"Detailed Usage","title":"Detailed Usage","text":"Bag of Little Boostrap (BLB) for linear mixed models.\nNumber of subsets: 10\nNumber of grouping factors per subset: 200\nNumber of bootstrap samples per subset: 500\nConfidence interval level: 95%\n\nVariance Components parameters\n─────────────────────────────────────────────────\n                    Estimate   CI Lower  CI Upper\n─────────────────────────────────────────────────\n(Intercept)       0.964051     0.881758  1.04793\nz1                3.1184       2.87197   3.37536\n(Intercept) : z1  0.00680443  -0.104531  0.120664\nResidual          1.46487      1.43443   1.4963\n─────────────────────────────────────────────────\n\nFixed-effect parameters\n─────────────────────────────────────────\n             Estimate  CI Lower  CI Upper\n─────────────────────────────────────────\n(Intercept)  0.981893  0.919381   1.04176\nx1           1.01022   0.991362   1.02862\nx2           1.0158    0.997535   1.03386\nx3           0.989067  0.971957   1.00621\n─────────────────────────────────────────","category":"page"},{"location":"man/detailed-usage/#Parallel-Processing","page":"Detailed Usage","title":"Parallel Processing","text":"","category":"section"},{"location":"man/detailed-usage/","page":"Detailed Usage","title":"Detailed Usage","text":"Compared to the traditional bootstrap method, which needs to repeatedly access the full data during the resampling step, BLB is much easier to parallelize because once subsets are taken, the resampling step only needs to access the small subsets. As a result, if our machine has N cores, then we can process N subsets in parallel to drastically speed up the analysis. ","category":"page"},{"location":"man/detailed-usage/","page":"Detailed Usage","title":"Detailed Usage","text":"This can be achieved by first adding worker nodes as follows:","category":"page"},{"location":"man/detailed-usage/","page":"Detailed Usage","title":"Detailed Usage","text":"using Distributed\naddprocs(2) # Use addprocs(N) if your machine has N cores\n@everywhere using MixedModelsBLB\nworkers()","category":"page"},{"location":"man/detailed-usage/","page":"Detailed Usage","title":"Detailed Usage","text":"4-element Array{Int64,1}:\n 2\n 3\n 7\n 8","category":"page"},{"location":"man/detailed-usage/","page":"Detailed Usage","title":"Detailed Usage","text":"Then we run BLB with the following code. Note that it is the same code as above because blb_full_data() will automatically make use of the worker nodes that we have just made available.","category":"page"},{"location":"man/detailed-usage/","page":"Detailed Usage","title":"Detailed Usage","text":"solver = Ipopt.IpoptSolver(print_level=0, max_iter=100, \n    mehrotra_algorithm = \"yes\", warm_start_init_point = \"yes\", \n    warm_start_bound_push = 1e-9)\n\nblb_ests = blb_full_data(\n        MersenneTwister(1),\n        dat;\n        feformula   = @formula(y ~ 1 + x1 + x2 + x3),\n        reformula   = @formula(y ~ 1 + x1),\n        id_name     = \"id\", \n        cat_names   = [\"x3\"], \n        subset_size = 100,\n        n_subsets   = 10, \n        n_boots     = 500,\n        solver      = solver,\n        verbose     = false,\n        nonparametric_boot = true\n    );","category":"page"},{"location":"man/detailed-usage/","page":"Detailed Usage","title":"Detailed Usage","text":"wks_schedule = [2, 3, 2, 3, 2, 3, 2, 3, 2, 3]\n      From worker 2:\t\n      From worker 2:\t******************************************************************************\n      From worker 2:\tThis program contains Ipopt, a library for large-scale nonlinear optimization.\n      From worker 2:\t Ipopt is released as open source code under the Eclipse Public License (EPL).\n      From worker 2:\t         For more information visit https://github.com/coin-or/Ipopt\n      From worker 2:\t******************************************************************************\n      From worker 2:\t\n      From worker 3:\t\n      From worker 3:\t******************************************************************************\n      From worker 3:\tThis program contains Ipopt, a library for large-scale nonlinear optimization.\n      From worker 3:\t Ipopt is released as open source code under the Eclipse Public License (EPL).\n      From worker 3:\t         For more information visit https://github.com/coin-or/Ipopt\n      From worker 3:\t******************************************************************************\n      From worker 3:","category":"page"},{"location":"man/detailed-usage/","page":"Detailed Usage","title":"Detailed Usage","text":"print(blb_ests)","category":"page"},{"location":"man/detailed-usage/","page":"Detailed Usage","title":"Detailed Usage","text":"Bag of Little Boostrap (BLB) for linear mixed models.\nNumber of subsets: 10\nNumber of grouping factors per subset: 200\nNumber of bootstrap samples per subset: 200\nConfidence interval level: 95%\n\nVariance Components parameters\n───────────────────────────────────────────────\n                  Estimate   CI Lower  CI Upper\n───────────────────────────────────────────────\n(Intercept)       0.97719   0.891017   1.06351\nx1                1.1049    0.996983   1.21472\n(Intercept) : x1  0.106918  0.0379043  0.175623\nResidual          1.0097    0.979607   1.03991\n───────────────────────────────────────────────\n\nFixed-effect parameters\n────────────────────────────────────────────\n              Estimate    CI Lower  CI Upper\n────────────────────────────────────────────\n(Intercept)  1.05446     0.962949   1.14765\nx1           0.941411    0.875429   1.00897\nx2           0.999205    0.976363   1.0208\nx3: M        0.0289467  -0.0967177  0.155865\n────────────────────────────────────────────","category":"page"},{"location":"man/detailed-usage/","page":"Detailed Usage","title":"Detailed Usage","text":"Note that the results are slightly different from above. This is because using multiple workers affect the random seeds used for subsetting and resampling, so the difference is due to sampling variability and will become smaller if we increase the number of subsets or the number of bootstrap samples.","category":"page"},{"location":"man/detailed-usage/#Customized-Confidence-Intervals","page":"Detailed Usage","title":"Customized Confidence Intervals","text":"","category":"section"},{"location":"man/detailed-usage/","page":"Detailed Usage","title":"Detailed Usage","text":"If you are interested in getting the confidence intervals of some functions of the parameters, you can construct it using the estimates stored in the output of blb_full_data(). ","category":"page"},{"location":"man/detailed-usage/","page":"Detailed Usage","title":"Detailed Usage","text":"To illustrate, suppose we want to calculate the 95% confidence interval of the Intra-class Correlation Coefficient (ICC). This can be done by calculating the 95% percentile CIs from all subsets and then average them across subsets. ","category":"page"},{"location":"man/detailed-usage/","page":"Detailed Usage","title":"Detailed Usage","text":"using LinearAlgebra, StatsBase\nicc   = zeros(200, 10)\nlevel = 0.95\n\n# Calculate ICC\nfor j in 1:10\n    for i in 1:200\n        # ICC = σa² / (σa² + σe²)\n        icc[i, j] = blb_ests.all_estimates[j].Σs[:, :, i][1, 1] / sum(diag(blb_ests.all_estimates[j].Σs[:, :, i]))\n    end\nend","category":"page"},{"location":"man/detailed-usage/","page":"Detailed Usage","title":"Detailed Usage","text":"# Calculate the 95% CIs on 10 subsets\nCIs = zeros(10, 2)\nfor j in 1:10\n    CIs[j, :] = StatsBase.percentile(icc[:, j], 100 * [(1 - level) / 2, 1 - (1-level) / 2])\nend","category":"page"},{"location":"man/detailed-usage/","page":"Detailed Usage","title":"Detailed Usage","text":"# Calculate the BLB CI by averaging CIs across subsets\nmean(CIs, dims = 1)","category":"page"},{"location":"man/detailed-usage/","page":"Detailed Usage","title":"Detailed Usage","text":"1×2 Array{Float64,2}:\n 0.435465  0.500777","category":"page"},{"location":"man/detailed-usage/#Tips","page":"Detailed Usage","title":"Tips","text":"","category":"section"},{"location":"man/detailed-usage/#Ipopt","page":"Detailed Usage","title":"Ipopt","text":"","category":"section"},{"location":"man/detailed-usage/","page":"Detailed Usage","title":"Detailed Usage","text":"By setting a higher print_level, you may notice that Ipopt performs lots of line searches. One way to remedy it and to speed up your analysis is to set mehrotra_algorithm=\"yes\", which disables line search. The option mu_strategy=\"adaptive\" may also be helpful.","category":"page"},{"location":"man/detailed-usage/#Categorical-Variables","page":"Detailed Usage","title":"Categorical Variables","text":"","category":"section"},{"location":"man/detailed-usage/","page":"Detailed Usage","title":"Detailed Usage","text":"To make sure that we do not miss any values of a categorical variable in a subset, blb_full_data() performs checking once a subset is taken. If a subset fails to contain certain values, then a new subset is taken and this step is repeated until we find a valid subset. ","category":"page"},{"location":"man/detailed-usage/","page":"Detailed Usage","title":"Detailed Usage","text":"This works as long as all values are relatively common. If a certain value is scarce, however, then it may take a long time to get a valid subset. In such cases, we recommend grouping the values into fewer categories. ","category":"page"},{"location":"man/detailed-usage/","page":"Detailed Usage","title":"Detailed Usage","text":"","category":"page"},{"location":"man/quick-tutorial/#Quick-Tutorial","page":"Quick Tutorial","title":"Quick Tutorial","text":"","category":"section"},{"location":"man/quick-tutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"Consider the sleepstudy dataset (Belenky et al., 2003), which is from a sleep deprivation study that measured the average reaction time from 18 subjects over 10 days.","category":"page"},{"location":"man/quick-tutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"using MixedModelsBLB, CSV, StatsModels, Random, Ipopt","category":"page"},{"location":"man/quick-tutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"sleepstudy = CSV.read(\"../../../test/data/sleepstudy.csv\");\nsleepstudy[1:10, :]","category":"page"},{"location":"man/quick-tutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"<table class=\"data-frame\"><thead><tr><th></th><th>Reaction</th><th>Days</th><th>id</th></tr><tr><th></th><th>Float64</th><th>Int64</th><th>Int64</th></tr></thead><tbody><p>10 rows × 3 columns</p><tr><th>1</th><td>249.56</td><td>0</td><td>308</td></tr><tr><th>2</th><td>258.705</td><td>1</td><td>308</td></tr><tr><th>3</th><td>250.801</td><td>2</td><td>308</td></tr><tr><th>4</th><td>321.44</td><td>3</td><td>308</td></tr><tr><th>5</th><td>356.852</td><td>4</td><td>308</td></tr><tr><th>6</th><td>414.69</td><td>5</td><td>308</td></tr><tr><th>7</th><td>382.204</td><td>6</td><td>308</td></tr><tr><th>8</th><td>290.149</td><td>7</td><td>308</td></tr><tr><th>9</th><td>430.585</td><td>8</td><td>308</td></tr><tr><th>10</th><td>466.353</td><td>9</td><td>308</td></tr></tbody></table>","category":"page"},{"location":"man/quick-tutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"To fit a Linear Mixed Model (LMM) of the form","category":"page"},{"location":"man/quick-tutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"textReaction  textDays + (1textID)","category":"page"},{"location":"man/quick-tutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"and perform statistical inference using the Bag of Little Bootstraps (BLB), we use the following code:","category":"page"},{"location":"man/quick-tutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"blb_ests = blb_full_data(\n        MersenneTwister(1),\n        sleepstudy;\n        feformula   = @formula(Reaction ~ 1 + Days),\n        reformula   = @formula(Reaction ~ 1),\n        id_name     = \"id\", \n        cat_names   = Array{String,1}(), \n        subset_size = 10,\n        n_subsets   = 20, \n        n_boots     = 500,\n        solver      = Ipopt.IpoptSolver(print_level=0),\n        verbose     = false,\n        nonparametric_boot = true\n    );","category":"page"},{"location":"man/quick-tutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"In this chunk,","category":"page"},{"location":"man/quick-tutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"MersenneTwister(1) sets the random seed for subsetting and resampling.\nfeformula and reformula specify the fixed and random effect formula, respectively.\nid_name is the name of the grouping factor such as subject ID.\ncat_names is a vector of categorical variable names. If there aren't any, simply set it as we did above. \nsubset_size, n_subsets, and n_boots are BLB parameters. Typically, we recommend setting\nsubset_size = N^06 or N^07, where N is the total number of subjects. \nn_subsets = 10-20.\nn_boots   = 500-2000\nIpopt is a freely-available gradient-based solver and works quite well. Mosek is 3-5 times faster than Ipopt but requires a liscense (you might be eligible for an academic liscense).","category":"page"},{"location":"man/quick-tutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"To see the result, type","category":"page"},{"location":"man/quick-tutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"print(blb_ests)","category":"page"},{"location":"man/quick-tutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"Bag of Little Boostrap (BLB) for linear mixed models.\nNumber of subsets: 20\nNumber of grouping factors per subset: 10\nNumber of bootstrap samples per subset: 500\nConfidence interval level: 95%\n\nVariance Components parameters\n─────────────────────────────────────────\n             Estimate  CI Lower  CI Upper\n─────────────────────────────────────────\n(Intercept)  1016.66    338.074   1752.28\nResidual      938.435   575.239   1367.96\n─────────────────────────────────────────\n\nFixed-effect parameters\n──────────────────────────────────────────\n             Estimate   CI Lower  CI Upper\n──────────────────────────────────────────\n(Intercept)  253.803   241.482     265.762\nDays          10.4451    7.72668    13.102\n──────────────────────────────────────────","category":"page"},{"location":"man/quick-tutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"Results are displayed in two tables, showing the BLB estimates and confidence intervals for both fixed effect and variance components parameters. ","category":"page"},{"location":"man/quick-tutorial/#Reference","page":"Quick Tutorial","title":"Reference","text":"","category":"section"},{"location":"man/quick-tutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"Gregory Belenky, Nancy J. Wesensten, David R. Thorne, Maria L. Thomas, Helen C. Sing, Daniel P. Redmond, Michael B. Russo and Thomas J. Balkin (2003) Patterns of performance degradation and restoration during sleep restriction and subsequent recovery: a sleep dose-response study. Journal of Sleep Research 12, 1–12.","category":"page"},{"location":"#MixedModelsBLB.jl-Documentation","page":"Home","title":"MixedModelsBLB.jl Documentation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"MixedModelsBLB.jl is a Julia package for analyzing massive longitudinal data using Linear Mixed Models (LMMs) through the Bag of Little Bootstrap (BLB) method. ","category":"page"},{"location":"#Package-Feature","page":"Home","title":"Package Feature","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Lightning fast compared to the traditional bootstrap-based LMM analysis.\nCompatible with a variety of data inputs:\nSupports inputs that integrate with the Tables.jl interface, inclusing the commonly used DataFrames.jl.\nSupports interfacing with databases, which is ideal for data sets that exceed the machine's memory limit.\nSupports parallel processing.\nSupports both gradient-based and gradient-free solvers such as Ipopt, Knitro, and Nlopt through the MathProgBase interface. ","category":"page"},{"location":"#Manual-Outline","page":"Home","title":"Manual Outline","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Pages = [\n    \"man/installation.md\",\n    \"man/quick-tutorial.md\",\n    \"man/detailed-usage.md\",\n    \"man/contributing.md\",\n    \"man/api.md\",\n]\nDepth = 2","category":"page"},{"location":"man/api/#API","page":"API","title":"API","text":"","category":"section"},{"location":"man/api/","page":"API","title":"API","text":"Documentation for MixedModelsBLB.jl's functions.","category":"page"},{"location":"man/api/#Index","page":"API","title":"Index","text":"","category":"section"},{"location":"man/api/","page":"API","title":"API","text":"Pages = [\"api.md\"]","category":"page"},{"location":"man/api/#Functions","page":"API","title":"Functions","text":"","category":"section"},{"location":"man/api/","page":"API","title":"API","text":"blb_one_subset\nblb_full_data\nblb_db\nSubsetEstimates\nblbEstimates\nconfint\nfixef\nvc","category":"page"},{"location":"man/api/#MixedModelsBLB.blb_one_subset","page":"API","title":"MixedModelsBLB.blb_one_subset","text":"blb_one_subset(rng, m; N, subset_size, n_boots, method, solver, verbose, nonparametric_boot)\n\nPerforms Bag of Little Bootstraps on a subset. \n\nPositional arguments\n\nrng: random number generator. Default to the global rng.\nm: an object of type blblmmModel or WSVarLmmModel\n\nKeyword arguments\n\nN: number of individuals/clusters in the full dataset.\nsubset_size: number of individuals/clusters in each subset.\nn_boots: number of bootstrap iterations. Default to 1000.\nmethod: a symbol, either :ML or :WiSER.\nsolver: solver for the optimization problem. \nverbose: Bool, whether to print bootstrap progress.\nnonparametric_boot: Bool, whether to use nonparametric bootstrap. For WiSER models, only nonparametric bootstrap is supported.\n\nValues\n\nsubset_estimates: an object of type SubsetEstimates\n\n\n\n\n\n","category":"function"},{"location":"man/api/#MixedModelsBLB.blb_full_data","page":"API","title":"MixedModelsBLB.blb_full_data","text":"blb_full_data(rng, datatable; feformula, reformula, wsvarformula, id_name, cat_names, subset_size, n_subsets, n_boots, method, solver, verbose,  nonparametric_boot)\n\nPerforms Bag of Little Bootstraps on the full dataset\n\nPositional arguments\n\nrng: random number generator. Default to the global rng.\ndatatable: a data table type that is compatible with Tables.jl. \n\nKeyword arguments\n\nfeformula: model formula for the fixed effects.\nreformula: model formula for the random effects.\nwsvarformula: model formula for the fixed effects of the within-subject variance. For linear mixed models, it should be @formula(y ~ 1). Only need to be specified when method = :WiSER. \nid_name: name of the cluster identifier variable. String.\ncat_names: a vector of the names of the categorical variables.\nsubset_size: number of clusters in the subset. \nn_subsets: number of subsets.\nn_boots: number of bootstrap iterations. Default to 1000\nsolver: solver for the optimization problem. \nmethod: fitting the model by maximum-likelihood (:ML) or GEE (:WiSER)\nverbose: Bool, whether to print bootstrap progress (percentage completion)\nnonparametric_boot: Bool, whether to use Nonparametric bootstrap\n\nValues\n\nresult: an object of the blbEstimates type\n\n\n\n\n\n","category":"function"},{"location":"man/api/#MixedModelsBLB.blb_db","page":"API","title":"MixedModelsBLB.blb_db","text":"blb_db(rng, con; feformula, reformula, id_name, cat_names, subset_size, n_subsets, n_boots, solver, verbose,  nonparametric_boot)\n\nPerforms Bag of Little Bootstraps on databases.\n\nPositional arguments\n\nrng: random number generator. Default to the global rng.\ncon: an object of type MySQL.Connection created by the function DBInterface.connect.\ntable_name: table name for the longitudinal data.\n\nKeyword arguments\n\nfeformula: model formula for the fixed effects.\nreformula: model formula for the random effects.\nid_name: name of the cluster identifier variable. String.\ncat_names: a vector of the names of the categorical variables.\nsubset_size: number of clusters in the subset. \nn_subsets: number of subsets.\nn_boots: number of bootstrap iterations. Default to 1000\nsolver: solver for the optimization problem. \nverbose: Bool, whether to print bootstrap progress (percentage completion)\nnonparametric_boot: Bool, whether to use Nonparametric bootstrap\n\nValues\n\nresult: an object of the blbEstimates type\n\n\n\n\n\n","category":"function"},{"location":"man/api/#MixedModelsBLB.SubsetEstimates","page":"API","title":"MixedModelsBLB.SubsetEstimates","text":"SubsetEstimates\n\nBLB linear mixed model estimates from one subset.\n\n\n\n\n\n","category":"type"},{"location":"man/api/#MixedModelsBLB.blbEstimates","page":"API","title":"MixedModelsBLB.blbEstimates","text":"blbEstimates\n\nBLB linear mixed model estimates, which contains blb parameters and a vector of SubsetEstimates.\n\n\n\n\n\n","category":"type"},{"location":"man/api/#MixedModelsBLB.confint","page":"API","title":"MixedModelsBLB.confint","text":"confint(subset_ests, level)\n\nCalculate confidence intervals using estimates from one subset.\n\nPositional arguments\n\nsubset_ests: an object of type SubsetEstimates\nlevel: confidence level, usually set to 0.95\n\n\n\n\n\nconfint(blb_ests, level)\n\nCalculate confidence intervals using estimates from all subsets.\n\nPositional arguments\n\nblb_ests: an object of type blbEstimates\nlevel: confidence level, usually set to 0.95\n\n\n\n\n\n","category":"function"},{"location":"man/installation/#Installation","page":"Installation","title":"Installation","text":"","category":"section"},{"location":"man/installation/","page":"Installation","title":"Installation","text":"This package requires Julia v1.4 or later, which can be obtained from https://julialang.org/downloads/.","category":"page"},{"location":"man/installation/","page":"Installation","title":"Installation","text":"To install the package, start Julia and type","category":"page"},{"location":"man/installation/","page":"Installation","title":"Installation","text":"using Pkg\nPkg.add(url = \"https://github.com/xinkai-zhou/MixedModelsBLB.jl\")","category":"page"},{"location":"man/installation/","page":"Installation","title":"Installation","text":"This does not install any solvers. If you don't have a solver installed already, you will want to install a solver such as Ipopt by running","category":"page"},{"location":"man/installation/","page":"Installation","title":"Installation","text":"Pkg.add(\"Ipopt\")","category":"page"}]
}
