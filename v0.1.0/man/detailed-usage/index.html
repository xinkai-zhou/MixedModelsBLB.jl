<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Detailed Usage · MixedModelsBLB.jl</title><script data-outdated-warner src="../../assets/warner.js"></script><link rel="canonical" href="https://xinkai-zhou.github.io/MixedModelsBLB.jl/man/detailed-usage/"/><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.039/juliamono-regular.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.11/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.png" alt="MixedModelsBLB.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">MixedModelsBLB.jl</a></span></div><form class="docs-search" action="../../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><a class="tocitem" href="../installation/">Installation</a></li><li><a class="tocitem" href="../quick-tutorial/">Quick Tutorial</a></li><li class="is-active"><a class="tocitem" href>Detailed Usage</a><ul class="internal"><li><a class="tocitem" href="#Data-Input"><span>Data Input</span></a></li><li><a class="tocitem" href="#Parallel-Processing"><span>Parallel Processing</span></a></li><li><a class="tocitem" href="#Customized-Confidence-Intervals"><span>Customized Confidence Intervals</span></a></li><li><a class="tocitem" href="#Tips"><span>Tips</span></a></li></ul></li><li><a class="tocitem" href="../contributing/">Contributing</a></li><li><a class="tocitem" href="../api/">API</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Detailed Usage</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Detailed Usage</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/xinkai-zhou/MixedModelsBLB.jl.git/blob/master/docs/src/man/detailed-usage.md#" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Detailed-Usage"><a class="docs-heading-anchor" href="#Detailed-Usage">Detailed Usage</a><a id="Detailed-Usage-1"></a><a class="docs-heading-anchor-permalink" href="#Detailed-Usage" title="Permalink"></a></h1><p>This page covers options you will need for dealing with extremely large longitudinal data sets and for forming estimates and confidence intervals of functions of the parameter estimates. </p><h2 id="Data-Input"><a class="docs-heading-anchor" href="#Data-Input">Data Input</a><a id="Data-Input-1"></a><a class="docs-heading-anchor-permalink" href="#Data-Input" title="Permalink"></a></h2><p>As shown in the <a href="../quick-tutorial/">Quick Tutorial</a> section, data can be loaded in memory (RAM) as a <code>DataFrame</code>. However, real-world longitudinal data such as Electronic Meidcal Records (EMR) may be too large to fit in RAM. </p><p>Fortunately, since the Bag of Little Bootstrap (BLB) method operates on subsets rather than the full data set, we do not need to load the full data in RAM. By interfacing with a database, we stream in subsets that are relevant to the analysis and leave the rest of the data on the hard disk. </p><p>To illustrate, we created a MySQL database called <code>MixedModelsBLB</code> on the local host and imported a simulated longitudinal data set with 1000 subjects and 20 measurements per subject to the <code>testdata</code> table. Covariates <span>$x_1, x_2, x_3, z_1$</span> are simulated from standard normal. </p><p>By providing a connection object, the <code>blb_db</code> function can interface with the database and only fetch data subsets that are relevant to the analysis. </p><pre><code class="language-julia hljs">using MixedModelsBLB, StatsModels, Random, Ipopt, DBInterface, MySQL, DataFrames</code></pre><pre><code class="language-julia hljs">con = DBInterface.connect(MySQL.Connection, &quot;127.0.0.1&quot;, &quot;USERNAME&quot;, &quot;PASSWORD&quot;; db = &quot;MixedModelsBLB&quot;);</code></pre><pre><code class="language-julia hljs"># Show the first 10 rows of the data set
DBInterface.execute(con,  &quot;SELECT * FROM testdata LIMIT 10;&quot;) |&gt; DataFrame</code></pre><p>&lt;table class=&quot;data-frame&quot;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;&lt;/th&gt;&lt;th&gt;id&lt;/th&gt;&lt;th&gt;y&lt;/th&gt;&lt;th&gt;x1&lt;/th&gt;&lt;th&gt;x2&lt;/th&gt;&lt;th&gt;x3&lt;/th&gt;&lt;th&gt;z1&lt;/th&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th&gt;&lt;/th&gt;&lt;th&gt;Int32&lt;/th&gt;&lt;th&gt;Float64&lt;/th&gt;&lt;th&gt;Float64&lt;/th&gt;&lt;th&gt;Float64&lt;/th&gt;&lt;th&gt;Float64&lt;/th&gt;&lt;th&gt;Float64&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;p&gt;10 rows × 6 columns&lt;/p&gt;&lt;tr&gt;&lt;th&gt;1&lt;/th&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;-1.74387&lt;/td&gt;&lt;td&gt;-1.72976&lt;/td&gt;&lt;td&gt;-1.28905&lt;/td&gt;&lt;td&gt;-1.47062&lt;/td&gt;&lt;td&gt;-0.267067&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th&gt;2&lt;/th&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;1.23021&lt;/td&gt;&lt;td&gt;0.795949&lt;/td&gt;&lt;td&gt;-0.33527&lt;/td&gt;&lt;td&gt;-0.535211&lt;/td&gt;&lt;td&gt;1.49908&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th&gt;3&lt;/th&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;0.495366&lt;/td&gt;&lt;td&gt;0.670062&lt;/td&gt;&lt;td&gt;0.0704676&lt;/td&gt;&lt;td&gt;-0.963544&lt;/td&gt;&lt;td&gt;0.797304&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th&gt;4&lt;/th&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;1.79272&lt;/td&gt;&lt;td&gt;0.550852&lt;/td&gt;&lt;td&gt;0.341794&lt;/td&gt;&lt;td&gt;-1.38511&lt;/td&gt;&lt;td&gt;-0.17164&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th&gt;5&lt;/th&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;3.33667&lt;/td&gt;&lt;td&gt;-0.0633746&lt;/td&gt;&lt;td&gt;1.73517&lt;/td&gt;&lt;td&gt;0.1343&lt;/td&gt;&lt;td&gt;-0.46908&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th&gt;6&lt;/th&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;4.35921&lt;/td&gt;&lt;td&gt;1.33694&lt;/td&gt;&lt;td&gt;1.29992&lt;/td&gt;&lt;td&gt;-0.616117&lt;/td&gt;&lt;td&gt;0.217624&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th&gt;7&lt;/th&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;3.05776&lt;/td&gt;&lt;td&gt;-0.0731486&lt;/td&gt;&lt;td&gt;0.206364&lt;/td&gt;&lt;td&gt;-1.71999&lt;/td&gt;&lt;td&gt;0.359146&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th&gt;8&lt;/th&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;-0.493603&lt;/td&gt;&lt;td&gt;-0.745464&lt;/td&gt;&lt;td&gt;-1.00886&lt;/td&gt;&lt;td&gt;0.320769&lt;/td&gt;&lt;td&gt;0.320025&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th&gt;9&lt;/th&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;-1.31595&lt;/td&gt;&lt;td&gt;-1.22006&lt;/td&gt;&lt;td&gt;-0.850056&lt;/td&gt;&lt;td&gt;-1.44737&lt;/td&gt;&lt;td&gt;0.259216&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th&gt;10&lt;/th&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;-0.446968&lt;/td&gt;&lt;td&gt;-0.0531773&lt;/td&gt;&lt;td&gt;1.12941&lt;/td&gt;&lt;td&gt;-0.492271&lt;/td&gt;&lt;td&gt;0.459696&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;</p><pre><code class="language-julia hljs">solver = Ipopt.IpoptSolver(print_level=0, max_iter=100, 
    mehrotra_algorithm = &quot;yes&quot;, warm_start_init_point = &quot;yes&quot;, 
    warm_start_bound_push = 1e-9)

blb_ests = blb_db(
        MersenneTwister(1),
        con,
        &quot;testdata&quot;,
        feformula   = @formula(y ~ 1 + x1 + x2 + x3),
        reformula   = @formula(y ~ 1 + z1),
        id_name     = &quot;id&quot;, 
        cat_names   = Vector{String}(), 
        subset_size = 200,
        n_subsets   = 10, 
        n_boots     = 500,
        solver      = solver,
        verbose     = false,
        nonparametric_boot = true
    );</code></pre><pre><code class="nohighlight hljs">******************************************************************************
This program contains Ipopt, a library for large-scale nonlinear optimization.
 Ipopt is released as open source code under the Eclipse Public License (EPL).
         For more information visit https://github.com/coin-or/Ipopt
******************************************************************************</code></pre><pre><code class="language-julia hljs">print(blb_ests)</code></pre><pre><code class="nohighlight hljs">Bag of Little Boostrap (BLB) for linear mixed models.
Number of subsets: 10
Number of grouping factors per subset: 200
Number of bootstrap samples per subset: 500
Confidence interval level: 95%

Variance Components parameters
─────────────────────────────────────────────────
                    Estimate   CI Lower  CI Upper
─────────────────────────────────────────────────
(Intercept)       0.964051     0.881758  1.04793
z1                3.1184       2.87197   3.37536
(Intercept) : z1  0.00680443  -0.104531  0.120664
Residual          1.46487      1.43443   1.4963
─────────────────────────────────────────────────

Fixed-effect parameters
─────────────────────────────────────────
             Estimate  CI Lower  CI Upper
─────────────────────────────────────────
(Intercept)  0.981893  0.919381   1.04176
x1           1.01022   0.991362   1.02862
x2           1.0158    0.997535   1.03386
x3           0.989067  0.971957   1.00621
─────────────────────────────────────────</code></pre><h2 id="Parallel-Processing"><a class="docs-heading-anchor" href="#Parallel-Processing">Parallel Processing</a><a id="Parallel-Processing-1"></a><a class="docs-heading-anchor-permalink" href="#Parallel-Processing" title="Permalink"></a></h2><p>Compared to the traditional bootstrap method, which needs to repeatedly access the full data during the resampling step, BLB is much easier to parallelize because once subsets are taken, the resampling step only needs to access the small subsets. As a result, if our machine has <span>$N$</span> cores, then we can process <span>$N$</span> subsets in parallel to drastically speed up the analysis. </p><p>This can be achieved by first adding worker nodes as follows:</p><pre><code class="language-julia hljs">using Distributed
addprocs(2) # Use addprocs(N) if your machine has N cores
@everywhere using MixedModelsBLB
workers()</code></pre><pre><code class="nohighlight hljs">4-element Array{Int64,1}:
 2
 3
 7
 8</code></pre><p>Then we run BLB with the following code. Note that it is the same code as above because <code>blb_full_data()</code> will automatically make use of the worker nodes that we have just made available.</p><pre><code class="language-julia hljs">solver = Ipopt.IpoptSolver(print_level=0, max_iter=100, 
    mehrotra_algorithm = &quot;yes&quot;, warm_start_init_point = &quot;yes&quot;, 
    warm_start_bound_push = 1e-9)

blb_ests = blb_full_data(
        MersenneTwister(1),
        dat;
        feformula   = @formula(y ~ 1 + x1 + x2 + x3),
        reformula   = @formula(y ~ 1 + x1),
        id_name     = &quot;id&quot;, 
        cat_names   = [&quot;x3&quot;], 
        subset_size = 100,
        n_subsets   = 10, 
        n_boots     = 500,
        solver      = solver,
        verbose     = false,
        nonparametric_boot = true
    );</code></pre><pre><code class="nohighlight hljs">wks_schedule = [2, 3, 2, 3, 2, 3, 2, 3, 2, 3]
      From worker 2:	
      From worker 2:	******************************************************************************
      From worker 2:	This program contains Ipopt, a library for large-scale nonlinear optimization.
      From worker 2:	 Ipopt is released as open source code under the Eclipse Public License (EPL).
      From worker 2:	         For more information visit https://github.com/coin-or/Ipopt
      From worker 2:	******************************************************************************
      From worker 2:	
      From worker 3:	
      From worker 3:	******************************************************************************
      From worker 3:	This program contains Ipopt, a library for large-scale nonlinear optimization.
      From worker 3:	 Ipopt is released as open source code under the Eclipse Public License (EPL).
      From worker 3:	         For more information visit https://github.com/coin-or/Ipopt
      From worker 3:	******************************************************************************
      From worker 3:</code></pre><pre><code class="language-julia hljs">print(blb_ests)</code></pre><pre><code class="nohighlight hljs">Bag of Little Boostrap (BLB) for linear mixed models.
Number of subsets: 10
Number of grouping factors per subset: 200
Number of bootstrap samples per subset: 200
Confidence interval level: 95%

Variance Components parameters
───────────────────────────────────────────────
                  Estimate   CI Lower  CI Upper
───────────────────────────────────────────────
(Intercept)       0.97719   0.891017   1.06351
x1                1.1049    0.996983   1.21472
(Intercept) : x1  0.106918  0.0379043  0.175623
Residual          1.0097    0.979607   1.03991
───────────────────────────────────────────────

Fixed-effect parameters
────────────────────────────────────────────
              Estimate    CI Lower  CI Upper
────────────────────────────────────────────
(Intercept)  1.05446     0.962949   1.14765
x1           0.941411    0.875429   1.00897
x2           0.999205    0.976363   1.0208
x3: M        0.0289467  -0.0967177  0.155865
────────────────────────────────────────────</code></pre><p>Note that the results are slightly different from above. This is because using multiple workers affect the random seeds used for subsetting and resampling, so the difference is due to sampling variability and will become smaller if we increase the number of subsets or the number of bootstrap samples.</p><h2 id="Customized-Confidence-Intervals"><a class="docs-heading-anchor" href="#Customized-Confidence-Intervals">Customized Confidence Intervals</a><a id="Customized-Confidence-Intervals-1"></a><a class="docs-heading-anchor-permalink" href="#Customized-Confidence-Intervals" title="Permalink"></a></h2><p>If you are interested in getting the confidence intervals of some functions of the parameters, you can construct it using the estimates stored in the output of <code>blb_full_data()</code>. </p><p>To illustrate, suppose we want to calculate the 95% confidence interval of the Intra-class Correlation Coefficient (ICC). This can be done by calculating the 95% percentile CIs from all subsets and then average them across subsets. </p><pre><code class="language-julia hljs">using LinearAlgebra, StatsBase
icc   = zeros(200, 10)
level = 0.95

# Calculate ICC
for j in 1:10
    for i in 1:200
        # ICC = σa² / (σa² + σe²)
        icc[i, j] = blb_ests.all_estimates[j].Σs[:, :, i][1, 1] / sum(diag(blb_ests.all_estimates[j].Σs[:, :, i]))
    end
end</code></pre><pre><code class="language-julia hljs"># Calculate the 95% CIs on 10 subsets
CIs = zeros(10, 2)
for j in 1:10
    CIs[j, :] = StatsBase.percentile(icc[:, j], 100 * [(1 - level) / 2, 1 - (1-level) / 2])
end</code></pre><pre><code class="language-julia hljs"># Calculate the BLB CI by averaging CIs across subsets
mean(CIs, dims = 1)</code></pre><pre><code class="nohighlight hljs">1×2 Array{Float64,2}:
 0.435465  0.500777</code></pre><h2 id="Tips"><a class="docs-heading-anchor" href="#Tips">Tips</a><a id="Tips-1"></a><a class="docs-heading-anchor-permalink" href="#Tips" title="Permalink"></a></h2><h3 id="Ipopt"><a class="docs-heading-anchor" href="#Ipopt">Ipopt</a><a id="Ipopt-1"></a><a class="docs-heading-anchor-permalink" href="#Ipopt" title="Permalink"></a></h3><p>By setting a higher <code>print_level</code>, you may notice that Ipopt performs lots of line searches. One way to remedy it and to speed up your analysis is to set <code>mehrotra_algorithm=&quot;yes&quot;</code>, which disables line search. The option <code>mu_strategy=&quot;adaptive&quot;</code> may also be helpful.</p><h3 id="Categorical-Variables"><a class="docs-heading-anchor" href="#Categorical-Variables">Categorical Variables</a><a id="Categorical-Variables-1"></a><a class="docs-heading-anchor-permalink" href="#Categorical-Variables" title="Permalink"></a></h3><p>To make sure that we do not miss any values of a categorical variable in a subset, <code>blb_full_data()</code> performs checking once a subset is taken. If a subset fails to contain certain values, then a new subset is taken and this step is repeated until we find a valid subset. </p><p>This works as long as all values are relatively common. If a certain value is scarce, however, then it may take a long time to get a valid subset. In such cases, we recommend grouping the values into fewer categories. </p><pre><code class="language-julia hljs"></code></pre></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../quick-tutorial/">« Quick Tutorial</a><a class="docs-footer-nextpage" href="../contributing/">Contributing »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.10 on <span class="colophon-date" title="Monday 22 November 2021 17:12">Monday 22 November 2021</span>. Using Julia version 1.6.4.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
